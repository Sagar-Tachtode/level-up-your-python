{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Level UP your Python\n",
    "\n",
    "### Henry Schreiner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%config InteractiveShell.ast_node_interactivity=\"last_expr_or_assign\"\n",
    "\n",
    "# Could enable pretty tracebacks (ONLY DO IN APPLICATION, NOT LIBRARY):\n",
    "# import rich.traceback\n",
    "# rich.traceback.install(show_locals=True)\n",
    "#\n",
    "# Or pretty-printing by default\n",
    "# rich.pretty.install()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "### Expected Knoledge\n",
    "\n",
    "You should already know:\n",
    "\n",
    "* Basic Python syntax\n",
    "* Functions\n",
    "* Basic classes (will cover quickly)\n",
    "* Basic NumPy (will mention)\n",
    "* Git - _CRITICAL FOR ANY SOFTWARE WORK!_\n",
    "\n",
    "And we will be using notebooks in JupyterLab, but won't be talking about them much, except for one disclaimer: They are for teaching, testing, prototyping, and final analysis driving - they are _NOT_ a place to store significant amounts of code! Refactor into a file once you have developed something!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can you expect?\n",
    "\n",
    "* I don't know what you know\n",
    "* We don't have time to study any topic in depth.\n",
    "\n",
    "So, we will move _fast_, and cover a _lot_.\n",
    "\n",
    "You are not expected to able to master everything you see.\n",
    "\n",
    "### Instead, you are expected to:\n",
    "\n",
    "1. Know what is possible, so you know to look for it\n",
    "2. Get pointers on where to look (lots of links!)\n",
    "3. Refer back to this material later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the author\n",
    "\n",
    "[![Henryiii's github stats](https://github-readme-stats.vercel.app/api?username=henryiii)](https://github.com/anuraghazra/github-readme-stats)\n",
    "\n",
    "https://iscinumpy.gitlab.io\n",
    "\n",
    "Scikit-HEP admin, member of IRIS-HEP.\n",
    "\n",
    "### Projects\n",
    "\n",
    "cibuildwheel • pybind11 • boost-histogram • Hist • Vector • CLI11 • Plumbum • GooFit • Particle • DecayLanguage • Conda-Forge ROOT • POVM\n",
    "\n",
    "### Intrests:\n",
    "\n",
    "Packaging and building • Bindings • Building a HEP analysis toolchain in Python, JITable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theory: New features in programming\n",
    "\n",
    "Programming is all about _orginization_. This is not always obvious, and has some odd consequences. Let's look at one: **new features remove functionality from the user**.\n",
    "\n",
    "Don't believe me? Pick one. Let's go with an old, simple one you should already know: `goto` vs. loops (`for`/`while`). (This is my favorite example, even though Python thankfully came along late enough to not even have `goto` in the first place, except as an April fools joke.)\n",
    "\n",
    "\n",
    "You have total power with goto! Jump from anywhere, too anywhere! You can recreate all loops with it, and more! So why are loops the newer, better feature?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**goto ([partially hypothetical](https://github.com/snoack/python-goto) in Python)**\n",
    "```python\n",
    "i = 0\n",
    "label .start\n",
    "print(f\"Hi {i}\")\n",
    "i + 1\n",
    "if i <= 10:\n",
    "    goto .start\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare to for loop:**\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(f\"Hi {i}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A programmer has to spend time to recognize what is happing in the first example - in the second example, even a fairly new Python programmer will immediatly say \"that prints 0 to 9\". The second example lets you build more complex programs, because you are working at a 'higher level', humans tend to do better which high level concepts (while computers work up from low level)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Object Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Everything in Python is an object!\n",
    "\n",
    "> Okay, technically a `PyObject*` in CPython - we'll focus on CPython most of the time today.\n",
    "\n",
    "An object is an \"instance\" of a \"type\", or a \"class\", which describes what that sort of object does.\n",
    "\n",
    "> Types and basic objects have some optimizations in CPython, for speed and also to keep the language from being infinitely recursive - but they are still PyObject*'s.\n",
    ">\n",
    "> Also, \"built-in\" classes are a little special."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v.bit_length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x: int) -> int:\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This really is an assignment, a new fuction is made and assigned to `f`. But, since the assignment is not arbitrary, that is, it clearly has a name, functions remember their name!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f.__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, v = v, f\n",
    "# What is the v now? f? How about the name?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting\n",
    "\n",
    "You can inspect objects. There are lots of ways.\n",
    "\n",
    "* In a juptyer notebook, use `object.<tab>` to bring up completions, shift tab for help.\n",
    "* You can use dir(object) to see all attribututes (more or less)\n",
    "* You can use help(object) or object? (IPython only) to see help\n",
    "* You can `import inspect` and use the tools there\n",
    "* You can install the rich library and use `rich.inspect()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x: float) -> float:\n",
    "    \"I am a square!\"\n",
    "    return x**2\n",
    "\n",
    "help(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import inspect\n",
    "print(inspect.getsourcefile(f))\n",
    "print(inspect.getsource(f))\n",
    "# WARNING! THIS DOES NOT ALWAYS WORK!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING: You cannot *always* see the source of a function, so this is a user trick, not one to use in a library!**\n",
    "\n",
    "Python does a three stage procedure when interpreting. It convers source to bytecode (pyc files), then runs the bytecode in the interpreter. When loading a file that has been run before (or came from a wheel, more on that later), it only loads the bytecode if the source hasn't changed - the source is not reparsed. So inspect works by looking up the original file location. _But you can delete the original file and run from bytecode only!_. Don't do that, but you can. Also, you can run from a zip file, and the orignal file might not be openable. And, finally, when running live in a REPL, there may not be a source (it works in IPython for us, though).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rich\n",
    "rich.inspect(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rich.inspect(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mutablity\n",
    "\n",
    "Many built-in objects are immutable, so it can hide the fact that Python does not have the concept of \"pass by value\"; the labels you see really are all pointing to PyObject*'s that are being managed by Python's garbage colllector.\n",
    "\n",
    "If you write `x = y`, then x and y refer to the same object. Always. This can't be overriden. However, it's hard to see that if you can't mutate the value, so there's no \"side effect\" to this. Side effects only happen for mutable objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 3\n",
    "y = x\n",
    "x += 1\n",
    "print(\"What is {y}?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try a mutable object. Lists, sets, and dicts are the most notable mutable objects in `builtins`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [3]\n",
    "y = x\n",
    "x[0] += 1\n",
    "print(\"What is {y = }?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why?\n",
    "\n",
    "The problem was that when the object was imuatable, the inplace operator `+=` actually behaved like `x = x + 1`, which is a new object. When it was a mutable object (a list), then it was able to change it in-place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Advanced aside: Why did this work?\n",
    "\n",
    "Quick aside for advanced Pythonistas, this is tricky. `x[0]` returns an int. So why is this any different than before? Let's explore, using mock:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest.mock import MagicMock\n",
    "\n",
    "ListProxy = MagicMock(\"ListProxy\")\n",
    "y = ListProxy()\n",
    "y[0] += 1\n",
    "rich.print(y.mock_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that this has special support for this syntax, it pulls out the item inside, and sets it, then stores it. There are other special syntax treatments in Python as well, all designed to make the language more friendly and powerful:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "1 < 2 < 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(not 3 in {1, 2, 3})\n",
    "print(3 not in {1, 2, 3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we glean anything from the original example, though? Yes, assignment is special. There are only three forms of normal assignment:\n",
    "\n",
    "```python\n",
    "x = y = 1\n",
    "x[y] = 2\n",
    "x.y = 3\n",
    "```\n",
    "\n",
    "That's it. These are _not_ valid assignments:\n",
    "\n",
    "```python\n",
    "x(y) = 1    # There is no assignment for __call__\n",
    "x + y = 2   # Arbitrary expressions are not allowed\n",
    "(x = 2) + 2 # Can't be nested\n",
    "# So on.\n",
    "```\n",
    "\n",
    "> This was limiting, so Python 3.8 added a nestable assignment, `:=` (walrus operator), though it was somewhat controversial. It does not work anywhere that normal `=` works, to avoid confusion.\n",
    "\n",
    "Inplace assignment operators follow the same rules, so they are \"special\", and not allowed anywhere."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scope\n",
    "\n",
    "Python has scope, but not in very many places. Functions and class definitions create scope, and modules have scope. (Generator expressions now have scope too). That's about it. So you can write this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:\n",
    "    x = 3\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If `if` had scope, then x would not be accessable outside the if. This is simple and useful, but you have to be careful to stay clean and tidy. For example, if that `if` was `False`, this would suddenly break. It's valid to use the loop varaible after a loop ends, ect. There's really not much scope at all!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because it shows up in so few places, and is so close to automatic, in can bite you once in a while if you don't keep it in mind:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 1\n",
    "def f() -> None:\n",
    "    print(x)\n",
    "    \n",
    "f()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we will try an assignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 1\n",
    "def f() -> None:\n",
    "    x = 2\n",
    "    print(x)\n",
    "    \n",
    "f()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So x in the function is not the same x out of the function now! (Try printing before assigning to it, or try changing it inplace. Even better, what happens if it is mutable?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want a rule to put in your pocket:\n",
    "* Accessing a variable uses the first variable it finds going up in scope\n",
    "* Setting a variable always uses the local scope"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If this is really what you want, you can use `nonlocal` to access a variable one-scope-up but not global, or `global` to declare a variable with global scope."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = 1\n",
    "def f() -> None:\n",
    "    global x\n",
    "    x = 2\n",
    "    print(x)\n",
    "    \n",
    "f()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need a pratical rule?\n",
    "\n",
    "**Always pass variables out explicilty, be cautious with using anything not clearly global in a function.**\n",
    "\n",
    "This means you should never see `global`, as it's only needed for setting variables. Global read-only variables (the only safe kind) are often ALL_CAPS."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory and the Garbage Collector\n",
    "\n",
    "Python is a garbage collected language. All Python objects have a refcount, which tells the garbage collector how many \"labels\" or how many ways you can access that object. When you can't get to the object anymore, the garbage collector _has the right to_ remove the object. It _usually_, depending on settings, runs rougly once per line, but it doesn't have to.\n",
    "\n",
    "As a consequence, _never_ depend on an object being deleted to perform some action at some time. More on that later, when we cover context managers.\n",
    "\n",
    "Let's look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import sys\n",
    "\n",
    "class Boom:\n",
    "    def __del__(self) -> None:\n",
    "        print(\"Boom!\")\n",
    "\n",
    "ob = Boom();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.is_tracked(ob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.getrefcount(ob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all went well, you probably should have seen \"Boom\" above. Now let's try a variation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ob = Boom()\n",
    "ob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del ob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice anything? Probably not. Objects only get deleted when the refcount goes to 0 (okay, technically 1, since the GC holds a refernce to it too; otherwise it wouldn't know what to delete. So it goes to 0 as it gets deleted by the gc). IPython tracks outputs; you can access all of them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Out[17]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There it is! Since we can access it, it's not collectable. (In fact, we can now access it from two Out's! )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's just one case where an object doesn't get garbaged collected until the final cleanup. You can also turn the garbage collector off, it could be running at a different setting, etc.\n",
    "\n",
    "Also, during the cleanup phase at the end, everything starts getting deleted. So even _modules_ might not be safe to call in cleanups. You have been warned.\n",
    "\n",
    "Don't use `__del__` in almost all cases, except for emergancy cleanup. There is a better way if you want \"action at a distance\", as I like to call it; we will see it when we get to context managers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing\n",
    "\n",
    "Caveat: A few minor details below will not be quite right for namespace packages, which do not contain an `__init__.py`. They are not heavily used, and designed for a specific purpose which we won't cover. And the only change is I'd have to be much more wordy but would still basically be saying the same things.\n",
    "\n",
    "### Importing Basics\n",
    "\n",
    "\n",
    "```python\n",
    "import a.b       # line 1\n",
    "from a import b  # line 2\n",
    "```\n",
    "\n",
    "So, question: is `b` a module (`b.py`), a package (`b/__init__.py`), or an object if line 1 is valid? How about 2?\n",
    "\n",
    "The rule: The left part must be a package. The right part of a `from ... import ...` statement can be anything.\n",
    "\n",
    "Any packages that appear in this statement have their `__init__.py` run unconditionally.\n",
    "\n",
    "So, a second question: is this valid?\n",
    "\n",
    "```python\n",
    "import a\n",
    "a.b\n",
    "```\n",
    "\n",
    "If `b` is a package or module, this only works it imported in `__init__.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where do imports come from?\n",
    "\n",
    "If I `import a`, where is `a`? Python works down sys.path:\n",
    "\n",
    "* `sys.path` _starts with_ `\".\"` - be careful about using this, and it _does_ override system site packages\n",
    "* Then the standard library follows\n",
    "* Then the system site packages and user site packages\n",
    "\n",
    "So a package containing `package/sys.py` is fine, even `package/__init__.py` will be able to import the normal `sys`, and has to import `package.sys` or `.sys` to get the local `sys.py`.\n",
    "\n",
    "> You may see `from __future__ import absolute_import`. This was from Python 2, causing the import system to work like Python 3 and prioritize the system site packages over local packages. With the default behavior, Python 2 could not access the system modules if a local module had the same name!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative imports\n",
    "\n",
    "```python\n",
    "from .sys import my_function\n",
    "```\n",
    "These can be moved around, but have some drawbacks. They only work in the syntax above (`from`), they only work when running _as_ a package (so a `__init__.py`), you can't use them in a non-library `__name__ == \"__main__\"` file that you direclty run (but `python -m ...` runs are fine)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object Oriented Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objects are _very_ powerful, and you can harness this power for your own designs!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Writing a class\n",
    "\n",
    "Writing a class should be second nature, and very natural to you - just as natural as writing a function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x: float) -> float:\n",
    "    return x**2\n",
    "\n",
    "print(f\"{f(3) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F:\n",
    "    def __call__(self, x: float) -> float:\n",
    "        return x**2\n",
    "    \n",
    "f = F()\n",
    "print(f\"{f(3) = }\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### Data + functions\n",
    "\n",
    "They allow you to bundle data with the functions that run on them. In a language like Python without (much) type overloading, this is important for design (and good for tab completion)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built in for Python 3.7+, install otherwise\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Vector:\n",
    "    def __init__(self, x: float, y: float) -> None:\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        \n",
    "    def mag(self) -> float:\n",
    "        return (self.x**2 + self.y**2)**.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Note: developing a class that represents data has a bit of boilerplate involved, so attrs (third-part) or dataclasses (first party in Python 3.7, thirdparty for 3.6) has a trick to make them _much more easily_, and automatically add things like nice repr's. We'll cover the parts of the syntax here later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Built in for Python 3.7+, install otherwise\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Vector:\n",
    "    x: float\n",
    "    y: float\n",
    "        \n",
    "    def mag(self) -> float:\n",
    "        return (self.x**2 + self.y**2)**.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = Vector(3,4)\n",
    "v.mag()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functors\n",
    "\n",
    "I just told you it was a bad idea to set something outside your local scope, and often not even a good idea to just view something outside the local scope. So how do you write something that has scope? Use a class as a functor! Compare this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_start = 0\n",
    "def incr() -> int:\n",
    "    global _start\n",
    "    _start += 1\n",
    "    return _start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Incr:\n",
    "    def __init__(self, incr: int = 0) -> None:\n",
    "        self.incr = incr\n",
    "    def __call__(self) -> int:\n",
    "        self.incr += 1\n",
    "        return self.incr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incr = Incr()\n",
    "incr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is explicit, clear, I can have multiple instances without having them interfere, I can see exactly what's going on without having to trace down a global, and I can even set the default value when I make the Incr instance!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modularity\n",
    "\n",
    "Let's say you have an algorithm with three parts. If you make a class that calls three member functions, you can allow a user to replace just one of the functions, and use the original first two. Classes are great for _originization_ and _code reuse_ because of this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunSomethingHard:\n",
    "    def part1(self) -> None:\n",
    "        print(\"Working hard\")\n",
    "    def part2(self) -> None:\n",
    "        print(\"Working harder\")\n",
    "    def part3(self) -> None:\n",
    "        print(\"That was hard!\")\n",
    "    def run(self) -> None:\n",
    "        self.part1()\n",
    "        self.part2()\n",
    "        self.part3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = RunSomethingHard()\n",
    "inst.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, look at how I can swap out part of the calculation without rewriting from scratch!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NewRunSomethingHard(RunSomethingHard):\n",
    "    def part2(self) -> None:\n",
    "        print(\"Nah, this is easy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst = NewRunSomethingHard()\n",
    "inst.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DSL (Domain Specific Language)\n",
    "\n",
    "You can customize almost every behavoir of a class to make them very natural for whatever you are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Path(str):\n",
    "    def __truediv__(self, other):\n",
    "        return self.__class__(f\"{self}/{other}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(\".\") / \"myfile\" / \"program.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Just in case you want to make a Path class like the one above - don't, use pathlib instead. We could ahve written `self.__class__` as `Path`, but then this would not subclass correctly and besides, using the class name inside the class is ugly and makes it harder to rename. If you return a normal string, then you can't keep applying `/`.\n",
    ">\n",
    "> Also, I left off type annoations for this example, as to do them properly I need to use a TypeVar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mixins (advanced)\n",
    "\n",
    "If you follow good practices, you can even make collections of behaviors and mix them into other classes - specifically, a mixin should not have an `__init__` or any new datamembers. (The second requirement is more important than the first, if you are carful to use `super()`. Let's rewrite the last example with mixins:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PathMixin:\n",
    "    def __truediv__(self, other):\n",
    "        return self.__class__(f\"{self}/{other}\")\n",
    "    \n",
    "class Path(str, PathMixin):\n",
    "    pass\n",
    "\n",
    "Path(\".\") / \"myfile\" / \"program.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Potentially show demo here?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Other: ABC, Protocols, and more\n",
    "\n",
    "Other useful things to look into are ABCs (Abstract Base Classes) and Protocols. These let you a) require certain methods be implemented by users, and b) formalize \"duck typing\". ABC's are a run-time feature, and kind of half-broken; you have to instanciate an ABC class to get the benefit of the checking. Protocols are a \"type-check time\" feature, and are far better and don't require special inheratince, but only are enforced by type checkers (see a later section!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design considerations\n",
    "\n",
    "Object oriented programming has been known to make it easy to create spegetti messes of code. The following tips will help you not fall into the trap and end up with poorly designed code. \"Make it a class\", by itself, will not magically make your code better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modular design\n",
    "\n",
    "You should break your code into _concepts_, and classes should help map those concepts to the computer. Different components of a detector might be classes, with an instance for each component. A vector, a URL, a remote data source, etc. You might have a class representing a unit of an analysis, and use either inheritance (okay) or a protocol (better, reduces coupling) to have real data processing vs. simulation generation. Etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unit test\n",
    "\n",
    "We will mention testing later, and there is another course on it, but I'm focusing on the word _unit_. You need to be able to run your classes standalone, in unit tests, and not only inplace. This keeps the design modular - you will resist the desire to make a class that needs a class to make another class inside a class that only works with the file that sits on your work laptop, etc. And you'll be free to redesign parts without having to worry about everything breaking down.\n",
    "\n",
    "Always use PyTest for unit testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Control flow and Features\n",
    "\n",
    "# Errors and catching them\n",
    "\n",
    "There are two types of errors in Python. A few really bad erros are segfaults. These are almost always something triggered via the C interace (such as by using `ctypes`), and are not due to problems your Python code. _Most_ errors in Python are part of the langauge, called Exceptions.\n",
    "\n",
    "An Exception is just a special control flow feature for things that are \"exceptional\"; often errors, but they are used for other things. In fact, internally, loops end by triggering a special exception!\n",
    "\n",
    "Exceptions \"bubble up\" through the stack to the outermost scope. If you catch an exception before it reaches the top, you can handle it. If you don't, then it shows up on the screen or in your logs as a traceback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment this to see an exception:\n",
    "# 1 / 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    1 / 0\n",
    "except ZeroDivisionError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exceptions use inhertance to form a tree structure, so you can be as tight or as loose as needed in catching them. Let's see the parents of Zero Division error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZeroDivisionError.__mro__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could catch any of these instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    1 / 0\n",
    "except ArithmeticError as e:\n",
    "    print(repr(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always catch the most narrow exception you can! Never try to catch a really broad class or all exceptions, because things like running out of memory, exit signals, and more are exceptions too, and you don't want to catch those if you didn't mean to!\n",
    "\n",
    "Here's a basic example of making your own:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNewException(RuntimeError):\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    raise MyNewException()\n",
    "except MyNewException:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There can be as many `except` blocks as you need, and there's also a `finally` block, which will always run, even if the exception is caught:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    1 / 0\n",
    "except ArithmeticError:\n",
    "    print(\"Caught the exception!\")\n",
    "finally:\n",
    "    print(\"I can run cleanup, regardless of what happens above!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where would you want something like this? How about closing a file!\n",
    "\n",
    "```python\n",
    "try:\n",
    "    f = open(...)\n",
    "    # do stuff with f that might throw an exception (basically anything)\n",
    "finally:\n",
    "    f.close()\n",
    "```\n",
    "\n",
    "This way, if an exception is thrown, the file still gets nicely closed. In fact, this is so important, we'll see a feature built around it soon!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generators (Iterators)\n",
    "\n",
    "Let's change topics just for a moment (we'll get to context managers in a moment, which we are building toward). Let's look into iterators, which are a form of generator. I'm sure you've seen one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(4):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what is `range(4)`? It's not a list, it's a custom object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python has built into it the concept of iteration. What the various looping structures do is call `iter()` on the object first, then call `next()` over and over until a `StopIteration` Exception is raised. Try it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(range(0, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "next(it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could implement `__iter__` and `__next__` yourself, but Python has a built in syntax shortcut for making iterators (and generators, which have a `__send__` too): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def range4():\n",
    "    yield 0\n",
    "    yield 1\n",
    "    yield 2\n",
    "    yield 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range4():\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The presence of a single yield anywhere in a function turns it into an iterator. Notice \"calling\" the iterator factory function just produces an iteratable object, it does not run anything yet. Then, when you iterate it, it \"pauses\" at each yield.\n",
    "\n",
    "Many Python functions take iterables, like `list` and `tuple`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(range4())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If Python were rewritten today, there would likley be a keyword, like `iter def`, to indicate that a `def` is making an iterator instead of a normal function; but for historical reasons, you just have to look for `yield`'s inside the function. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decorators\n",
    "\n",
    "This is likely the simplest syntactic sugar you'll see today, but maybe one with some of the furthest reaching consequences. Let's say you have a bit of code that looks like this:\n",
    "\n",
    "```python\n",
    "def f(): ...\n",
    "f = g(f)\n",
    "```\n",
    "\n",
    "So `g` is a function that takes a function and (hopefully) returns a function, probably a very similar one since you are giving it the same name as the old \"f\". In Python 2.5, we gained the ability to write this instead:\n",
    "\n",
    "```python\n",
    "@g\n",
    "def f(): ...\n",
    "```\n",
    "\n",
    "That's it. The thing after the `@` \"decorates\" (or transforms) the function you are defining and the output is saved with the name `f`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bad_decorator(func):\n",
    "    print(f\"You don't need {func.__name__}!\")\n",
    "    return 2\n",
    "\n",
    "@bad_decorator\n",
    "def f(x):\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, so that's useless (well, except for the printout, which could be good for logging). What could this be used for? Turns out, almost anything. Having a syntax for \"modifying\" a function (it also works on methods and classes, too) is fantastic, and lets you think in a different way.\n",
    "\n",
    "There are several decorators in builtins, `property`, `classmethod`, and `staticmethod`. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BagOfFunctions:\n",
    "    @staticmethod\n",
    "    def f(x):\n",
    "        return f**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's missing from the above function? Self! It's static, it doesn't need an instance, or even the current class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BagOfFunctions.f(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BagOfFunctions().f(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The decorator took our method and added the correct handling to it so it works with or without an instance.\n",
    "\n",
    "If the thing after the `@` is called, this is called a decorator factory; it's exactly the same as above, just slightly more unusual in structure to what you normally see:\n",
    "\n",
    "```python\n",
    "def f...\n",
    "f = g()(f)\n",
    "\n",
    "# same as\n",
    "\n",
    "@g()\n",
    "def f...\n",
    "```\n",
    "\n",
    "You can also nest decorators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could have a rate decorator, which causes a function to wait after completing so that it always takes the same amount of time. You could have a logging decorator, which prints to a log every time the wrapped function is called. There are quite a few decorators in the standard library; we'll see more later, but here are a couple interesting ones:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Least Recently Used Caching\n",
    "\n",
    "This is all you need to implement a cache based on the input arguments. When you call this again with recently used arguments (the cache size is adjustable), it pulls from a cache instead of rerunning the function. (Note: parentheses on this one are optional in Python 3.8, it's both a decorator and a decorator factory starting in 3.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import time\n",
    "\n",
    "@functools.lru_cache()\n",
    "def slow(x: int) -> int:\n",
    "    time.sleep(2)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slow(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another magical decorator is `functools.singledispatch`, which lets you simulate type based dispatch (but only on the first argument) from other langauges:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.singledispatch\n",
    "def square(x):\n",
    "    print(\"Not implemented\")\n",
    "\n",
    "@square.register\n",
    "def square_int(x: int) -> int:\n",
    "    return x**2\n",
    "\n",
    "@square.register\n",
    "def square_str(x: str) -> str:\n",
    "    return f\"{x}²\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square(\"x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's also `@functools.total_ordering`, which when applied to a class, fills in the missing comparison operators from the ones that are already there (`==`, `!=`, `<`, `<=`, `>`, `>=` can be computed from just two functions)\n",
    "\n",
    "And `@functools.wraps` is a decorator that helps you write decorators that wrap functions. Also see decorator and the newer, fancier wrapt libraries on PyPI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another use case we've breifly seen is dataclasses from Python 3.7:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class Vector:\n",
    "    x: float\n",
    "    y: float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This `@dataclass` is taking the class you pass in, converting the class annotations to instance variables, making an `__init__`, `__repr__`, and much more. When you are viewing a class as data + functionality, this is a very natural way to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vector(1, y=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you need Dataclasses in 3.6, there's a pip install dataclasses backport, and this was based on the popular `attrs` library, which is much more powerful and can do all sorts of tricks, like validate and transform values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`click` is a package that lets you write command line interfaces using decorators on functions:\n",
    "\n",
    "```python\n",
    "import click\n",
    "\n",
    "@click.command()\n",
    "@click.option('--count', default=1, help='Number of greetings.')\n",
    "@click.option('--name', prompt='Your name',\n",
    "              help='The person to greet.')\n",
    "def hello(count, name):\n",
    "    \"\"\"Simple program that greets NAME for a total of COUNT times.\"\"\"\n",
    "    for x in range(count):\n",
    "        click.echo('Hello %s!' % name)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    hello()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll see more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context Managers\n",
    "\n",
    "Yes! Our journey is complete, we are where I wanted to be. Context managers are one of my favorites, and a little underused, expecially in user code, when they are really easy to both write and use (while decorators, for comparison, are really easy to use but a bit tricky to write). A context manager has a specific purpose.\n",
    "\n",
    "The first is what I call \"action at a distance\". It lets you schedule an action for later that is sure to always happen (unless you get a segfault, or exit a really nasty way). This is likely the most famous context manager:\n",
    "\n",
    "```python\n",
    "with open(...) as f:\n",
    "    txt = f.readlines()\n",
    "```\n",
    "\n",
    "When you enter the with block, `__enter__` is called and the result is assigned to the `as` target, if there is one. Then when you leave the block, `__exit__` is called. If you leave via an exception, `__exit__` gets special arguments that let you even decide what to do based on that the exception is - or even handle the exception and continue. `contextlib` has several simple context managers, like `redirect_stdout`, `redirect_stdout`, and `suppress`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "\n",
    "with contextlib.suppress(ZeroDivisionError):\n",
    "    1 / 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But the real star of contextlib is `contextmanager`, which is a decorator that makes writing contextmanagers really easy. Let's try one of my favorites, a timer context manager:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextlib.contextmanager\n",
    "def timer():\n",
    "    old_time = time.monotonic()\n",
    "    try:\n",
    "        yield\n",
    "    finally:\n",
    "        new_time = time.monotonic()\n",
    "        print(f\"Time taken: {new_time - old_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with timer():\n",
    "    print(\"Start\")\n",
    "    time.sleep(1.5)\n",
    "    print(\"End\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an extra bonus, `contextmanager` uses `ContextDecorator`, so the objects it makes can also be used as Dectorators! [Pretty much everything](https://docs.python.org/3/library/contextlib.html) in the `contextlib` module that does not have the word `async` in it is worth learning. `contextlib.closing` turns an object with a `.close()` into a context manager, and `contextlib.ExitStack` lets you nest context managers without eating up massive amounts of whitespace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@timer()\n",
    "def long_function():\n",
    "    print(\"Start\")\n",
    "    time.sleep(1.5)\n",
    "    print(\"End\")\n",
    "    \n",
    "long_function()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick note: Async\n",
    "\n",
    "Everything we've been doing has built on itself, and we seemed to be going somewhere; the pinnicle of this direction was asctually not context managers, but `async/await`. All of this feeds into `async/await`, which was formally interoduced as a langauage component in Python 3.6. However, we did skip two neccesary steps; we didn't talk about generators (iterators can actually \"send\" values in, not just produce them, but there's no specific constuct for doing that, like there is for consuming values in a for loop), and we didn't talk about `yield from`, which lets you put an iterator or generator inside another one. The main reason we didn't try to reach `async` though is that I've never found a great use for it in scientific programming; it is much more intrusive than normal threading, it doesn't really \"live\" side-by-side with normal syncronious programming all that well (it's better now, though), and the libraries for it are a little young. Feel free to investigate on your own, though! I've also discussed the mechanisms behind it in detail in my blog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Static Type Hinting\n",
    "\n",
    "The most exciting thing happening right now in Python development is static typing. Since Python 3.0, we've had function annoations, and since 3.6, variable annoations. In 3.5, we got a \"typing\" library, which provides tools to describe types. You've already seen me using type hints:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x: int) -> int:\n",
    "    return x * 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might have been asking yourself, what does that do? Does it limit what I can use here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f([\"hi\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No. It does nothing at runtime, except store the object. And in the upcoming Python 3.10 (or 3.7+ with `from __future__ import annotations`, it doen't even store the actual object, just the string you type here.\n",
    "\n",
    "It is not useless though! For one, it helps the reader. Knowing the types expected really gives you a much better idea of what is going on and what you can do and can't do.\n",
    "\n",
    "But the key goal is: static type checking! There are a collection of static type checkers, the most \"offical\" and famous of which is MyPy. You can think of this as the \"compiler\" for compiled languages like C++; it checks to make sure you are not lying about the types. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tmp_mypy1.py\n",
    "def f(x: int) -> int:\n",
    "    return x * 5\n",
    "\n",
    "f([\"hi\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mypy tmp_mypy1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go! And, most importantly, _we didn't have to run any code to see this error_! Your tests cannot test every possible branch, every line of code. MyPy can (though it doesn't by default, due to gradual typing). You may have code that runs rarely, that requires remote resources, that is slow, etc. All those can be checked by MyPy. It also keeps you (too?) truthful in your types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see an exmaple of an error that MyPy can catch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile tmp_mypy1.py\n",
    "from typing import Optional\n",
    "\n",
    "def f(x: Optional[int]) -> Optional[int]:\n",
    "    return x * 5\n",
    "\n",
    "f(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mypy tmp_mypy1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your test suite may have forgotton to run with a None input. You may not run into None often, until you are in a critical situation. But MyPy can find it and tell you there's a logic issue, your function cannot take `None` like it claims it can."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Personally, I recommend using pre-commit to run all your checks except pytest (and that only because it's likely slow), and including mypy in your pre-commit testing. Try to turn on as much as possible, and increase it until you can run with full `strict` checking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packaging and Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTest: Unit Testing\n",
    "# NumPy: You should know this one\n",
    "# Pandas: DataFrames for Python\n",
    "# Numba: JIT for Speed!\n",
    "# Pybind11: Use C++ libraries\n",
    "# Code Quality and CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:level-up-your-python] *",
   "language": "python",
   "name": "conda-env-level-up-your-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc-autonumbering": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
